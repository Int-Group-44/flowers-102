{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Int-Group-44/flowers-102/blob/main/OxfordFlowers102CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "egaLH944BBD5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "dataset, dataset_info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "dataset_info\n",
        "test_set, training_set, validation_set = dataset['test'], dataset['train'], dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JAGNFt3PGE",
        "outputId": "d3f4ba23-f401-4389-c4f8-7881302c20de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgSxJm7OYeKN"
      },
      "source": [
        "Importing TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ql9q6LSWMZRk"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "num_training_examples = 1020\n",
        "num_validation_examples = 1020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xwksk4asQhtr"
      },
      "outputs": [],
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    #label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "BATCH_SIZE = 16\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.shuffle(num_validation_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9WgfAXPgjFd5"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.RandomFlip(\"horizontal_and_vertical\", input_shape=input_shape))\n",
        "  model.add(layers.RandomRotation(180))\n",
        "  model.add(layers.RandomZoom(0.3))\n",
        "  model.add(layers.RandomContrast(factor=(0.0, 1)))\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tF9v2wo9F8LW"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = make_model(input_shape=(IMAGE_RES, IMAGE_RES) + (3,), num_classes=102)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumHmqXelH38",
        "outputId": "0c01f11a-d59c-428d-ff51-da5edf1398fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "64/64 [==============================] - 20s 155ms/step - loss: 5.2317 - accuracy: 0.0098 - val_loss: 4.6523 - val_accuracy: 0.0098\n",
            "Epoch 2/150\n",
            "64/64 [==============================] - 10s 152ms/step - loss: 4.8159 - accuracy: 0.0137 - val_loss: 4.7127 - val_accuracy: 0.0108\n",
            "Epoch 3/150\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 4.7757 - accuracy: 0.0167 - val_loss: 4.7574 - val_accuracy: 0.0108\n",
            "Epoch 4/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 4.6815 - accuracy: 0.0147 - val_loss: 4.7276 - val_accuracy: 0.0118\n",
            "Epoch 5/150\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 4.6448 - accuracy: 0.0186 - val_loss: 4.6887 - val_accuracy: 0.0127\n",
            "Epoch 6/150\n",
            "64/64 [==============================] - 10s 152ms/step - loss: 4.6007 - accuracy: 0.0275 - val_loss: 4.6584 - val_accuracy: 0.0206\n",
            "Epoch 7/150\n",
            "64/64 [==============================] - 11s 163ms/step - loss: 4.5515 - accuracy: 0.0255 - val_loss: 4.6248 - val_accuracy: 0.0245\n",
            "Epoch 8/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 4.5204 - accuracy: 0.0304 - val_loss: 4.5565 - val_accuracy: 0.0284\n",
            "Epoch 9/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 4.4663 - accuracy: 0.0422 - val_loss: 4.4813 - val_accuracy: 0.0314\n",
            "Epoch 10/150\n",
            "64/64 [==============================] - 11s 159ms/step - loss: 4.4095 - accuracy: 0.0510 - val_loss: 4.3622 - val_accuracy: 0.0520\n",
            "Epoch 11/150\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 4.4012 - accuracy: 0.0461 - val_loss: 4.2878 - val_accuracy: 0.0745\n",
            "Epoch 12/150\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 4.3615 - accuracy: 0.0500 - val_loss: 4.2289 - val_accuracy: 0.0804\n",
            "Epoch 13/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 4.3157 - accuracy: 0.0588 - val_loss: 4.1808 - val_accuracy: 0.0824\n",
            "Epoch 14/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 4.2455 - accuracy: 0.0657 - val_loss: 4.1198 - val_accuracy: 0.1000\n",
            "Epoch 15/150\n",
            "64/64 [==============================] - 10s 153ms/step - loss: 4.2254 - accuracy: 0.0775 - val_loss: 4.0755 - val_accuracy: 0.1167\n",
            "Epoch 16/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 4.1448 - accuracy: 0.0922 - val_loss: 4.0198 - val_accuracy: 0.1137\n",
            "Epoch 17/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 4.1129 - accuracy: 0.0833 - val_loss: 3.9671 - val_accuracy: 0.1176\n",
            "Epoch 18/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 4.0758 - accuracy: 0.1039 - val_loss: 3.9134 - val_accuracy: 0.1343\n",
            "Epoch 19/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 4.0501 - accuracy: 0.1020 - val_loss: 3.8984 - val_accuracy: 0.1402\n",
            "Epoch 20/150\n",
            "64/64 [==============================] - 12s 189ms/step - loss: 3.9671 - accuracy: 0.1147 - val_loss: 3.8665 - val_accuracy: 0.1471\n",
            "Epoch 21/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 3.9098 - accuracy: 0.1147 - val_loss: 3.8033 - val_accuracy: 0.1529\n",
            "Epoch 22/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 3.9018 - accuracy: 0.1235 - val_loss: 3.7702 - val_accuracy: 0.1696\n",
            "Epoch 23/150\n",
            "64/64 [==============================] - 10s 157ms/step - loss: 3.8564 - accuracy: 0.1235 - val_loss: 3.7504 - val_accuracy: 0.1667\n",
            "Epoch 24/150\n",
            "64/64 [==============================] - 10s 140ms/step - loss: 3.8958 - accuracy: 0.1235 - val_loss: 3.7288 - val_accuracy: 0.1637\n",
            "Epoch 25/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.8636 - accuracy: 0.1235 - val_loss: 3.7281 - val_accuracy: 0.1588\n",
            "Epoch 26/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 3.6824 - accuracy: 0.1578 - val_loss: 3.6533 - val_accuracy: 0.1765\n",
            "Epoch 27/150\n",
            "64/64 [==============================] - 10s 154ms/step - loss: 3.7338 - accuracy: 0.1373 - val_loss: 3.6300 - val_accuracy: 0.1892\n",
            "Epoch 28/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 3.7049 - accuracy: 0.1529 - val_loss: 3.5873 - val_accuracy: 0.1990\n",
            "Epoch 29/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.6657 - accuracy: 0.1480 - val_loss: 3.5476 - val_accuracy: 0.2059\n",
            "Epoch 30/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.5702 - accuracy: 0.1824 - val_loss: 3.5248 - val_accuracy: 0.2069\n",
            "Epoch 31/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 3.5891 - accuracy: 0.1676 - val_loss: 3.5127 - val_accuracy: 0.2108\n",
            "Epoch 32/150\n",
            "64/64 [==============================] - 10s 152ms/step - loss: 3.5759 - accuracy: 0.1824 - val_loss: 3.5074 - val_accuracy: 0.2049\n",
            "Epoch 33/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 3.5035 - accuracy: 0.1765 - val_loss: 3.4689 - val_accuracy: 0.2167\n",
            "Epoch 34/150\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 3.4884 - accuracy: 0.1755 - val_loss: 3.4234 - val_accuracy: 0.2098\n",
            "Epoch 35/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.4495 - accuracy: 0.2098 - val_loss: 3.4115 - val_accuracy: 0.2294\n",
            "Epoch 36/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 3.3772 - accuracy: 0.2206 - val_loss: 3.3971 - val_accuracy: 0.2275\n",
            "Epoch 37/150\n",
            "64/64 [==============================] - 10s 157ms/step - loss: 3.4581 - accuracy: 0.1843 - val_loss: 3.3898 - val_accuracy: 0.2431\n",
            "Epoch 38/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.3985 - accuracy: 0.1961 - val_loss: 3.3861 - val_accuracy: 0.2216\n",
            "Epoch 39/150\n",
            "64/64 [==============================] - 10s 140ms/step - loss: 3.3298 - accuracy: 0.2314 - val_loss: 3.3235 - val_accuracy: 0.2471\n",
            "Epoch 40/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 3.3124 - accuracy: 0.2118 - val_loss: 3.3223 - val_accuracy: 0.2461\n",
            "Epoch 41/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.2669 - accuracy: 0.2127 - val_loss: 3.2992 - val_accuracy: 0.2363\n",
            "Epoch 42/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 3.2094 - accuracy: 0.2353 - val_loss: 3.2770 - val_accuracy: 0.2373\n",
            "Epoch 43/150\n",
            "64/64 [==============================] - 10s 140ms/step - loss: 3.2285 - accuracy: 0.2284 - val_loss: 3.2441 - val_accuracy: 0.2431\n",
            "Epoch 44/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.0802 - accuracy: 0.2529 - val_loss: 3.2427 - val_accuracy: 0.2431\n",
            "Epoch 45/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.1717 - accuracy: 0.2539 - val_loss: 3.2290 - val_accuracy: 0.2451\n",
            "Epoch 46/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 3.2027 - accuracy: 0.2333 - val_loss: 3.1842 - val_accuracy: 0.2647\n",
            "Epoch 47/150\n",
            "64/64 [==============================] - 10s 158ms/step - loss: 3.0325 - accuracy: 0.2647 - val_loss: 3.1943 - val_accuracy: 0.2706\n",
            "Epoch 48/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.0184 - accuracy: 0.2833 - val_loss: 3.1437 - val_accuracy: 0.2716\n",
            "Epoch 49/150\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 2.9802 - accuracy: 0.2882 - val_loss: 3.1155 - val_accuracy: 0.2745\n",
            "Epoch 50/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.0514 - accuracy: 0.2539 - val_loss: 3.1616 - val_accuracy: 0.2637\n",
            "Epoch 51/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.9502 - accuracy: 0.2833 - val_loss: 3.1287 - val_accuracy: 0.2725\n",
            "Epoch 52/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.9568 - accuracy: 0.2873 - val_loss: 3.1018 - val_accuracy: 0.2716\n",
            "Epoch 53/150\n",
            "64/64 [==============================] - 9s 141ms/step - loss: 2.9190 - accuracy: 0.2853 - val_loss: 3.0735 - val_accuracy: 0.2824\n",
            "Epoch 54/150\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 2.8877 - accuracy: 0.2931 - val_loss: 3.0986 - val_accuracy: 0.2676\n",
            "Epoch 55/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 2.8672 - accuracy: 0.2951 - val_loss: 3.0948 - val_accuracy: 0.2755\n",
            "Epoch 56/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.8492 - accuracy: 0.2755 - val_loss: 3.0624 - val_accuracy: 0.2863\n",
            "Epoch 57/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.7998 - accuracy: 0.3167 - val_loss: 3.0309 - val_accuracy: 0.2892\n",
            "Epoch 58/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.7972 - accuracy: 0.2912 - val_loss: 3.0038 - val_accuracy: 0.2873\n",
            "Epoch 59/150\n",
            "64/64 [==============================] - 10s 156ms/step - loss: 2.7341 - accuracy: 0.3304 - val_loss: 3.0235 - val_accuracy: 0.2814\n",
            "Epoch 60/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.8123 - accuracy: 0.2931 - val_loss: 2.9994 - val_accuracy: 0.2912\n",
            "Epoch 61/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.7594 - accuracy: 0.3176 - val_loss: 3.0033 - val_accuracy: 0.2843\n",
            "Epoch 62/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.6852 - accuracy: 0.3343 - val_loss: 2.9911 - val_accuracy: 0.2794\n",
            "Epoch 63/150\n",
            "64/64 [==============================] - 12s 189ms/step - loss: 2.6811 - accuracy: 0.3294 - val_loss: 2.9998 - val_accuracy: 0.2971\n",
            "Epoch 64/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.6234 - accuracy: 0.3373 - val_loss: 2.9299 - val_accuracy: 0.3069\n",
            "Epoch 65/150\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 2.6080 - accuracy: 0.3451 - val_loss: 2.9475 - val_accuracy: 0.3039\n",
            "Epoch 66/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.6806 - accuracy: 0.3431 - val_loss: 2.9168 - val_accuracy: 0.3176\n",
            "Epoch 67/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.5944 - accuracy: 0.3559 - val_loss: 2.9335 - val_accuracy: 0.3098\n",
            "Epoch 68/150\n",
            "64/64 [==============================] - 11s 160ms/step - loss: 2.5939 - accuracy: 0.3608 - val_loss: 2.9238 - val_accuracy: 0.3137\n",
            "Epoch 69/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.5551 - accuracy: 0.3382 - val_loss: 2.9635 - val_accuracy: 0.3196\n",
            "Epoch 70/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.5477 - accuracy: 0.3775 - val_loss: 2.9469 - val_accuracy: 0.3059\n",
            "Epoch 71/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.5682 - accuracy: 0.3510 - val_loss: 2.9366 - val_accuracy: 0.3235\n",
            "Epoch 72/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.5308 - accuracy: 0.3716 - val_loss: 2.9018 - val_accuracy: 0.3235\n",
            "Epoch 73/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.4690 - accuracy: 0.3637 - val_loss: 2.9131 - val_accuracy: 0.3167\n",
            "Epoch 74/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.4420 - accuracy: 0.3961 - val_loss: 2.9177 - val_accuracy: 0.3284\n",
            "Epoch 75/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 2.4004 - accuracy: 0.3706 - val_loss: 2.9206 - val_accuracy: 0.3196\n",
            "Epoch 76/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.4277 - accuracy: 0.3971 - val_loss: 2.9380 - val_accuracy: 0.3216\n",
            "Epoch 77/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.4034 - accuracy: 0.3745 - val_loss: 2.8710 - val_accuracy: 0.3245\n",
            "Epoch 78/150\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.4013 - accuracy: 0.3853 - val_loss: 2.9209 - val_accuracy: 0.3206\n",
            "Epoch 79/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.3082 - accuracy: 0.4029 - val_loss: 2.8721 - val_accuracy: 0.3275\n",
            "Epoch 80/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.2982 - accuracy: 0.4176 - val_loss: 2.9454 - val_accuracy: 0.3157\n",
            "Epoch 81/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.3123 - accuracy: 0.4176 - val_loss: 2.9426 - val_accuracy: 0.3069\n",
            "Epoch 82/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 2.2708 - accuracy: 0.4147 - val_loss: 2.9032 - val_accuracy: 0.3176\n",
            "Epoch 83/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.2736 - accuracy: 0.4069 - val_loss: 2.9029 - val_accuracy: 0.3216\n",
            "Epoch 84/150\n",
            "64/64 [==============================] - 10s 151ms/step - loss: 2.2852 - accuracy: 0.4245 - val_loss: 2.8528 - val_accuracy: 0.3471\n",
            "Epoch 85/150\n",
            "64/64 [==============================] - 11s 163ms/step - loss: 2.2354 - accuracy: 0.4186 - val_loss: 2.8641 - val_accuracy: 0.3265\n",
            "Epoch 86/150\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 2.1669 - accuracy: 0.4490 - val_loss: 2.8742 - val_accuracy: 0.3216\n",
            "Epoch 87/150\n",
            "64/64 [==============================] - 10s 148ms/step - loss: 2.2189 - accuracy: 0.4147 - val_loss: 2.8880 - val_accuracy: 0.3196\n",
            "Epoch 88/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 2.1679 - accuracy: 0.4382 - val_loss: 2.8745 - val_accuracy: 0.3284\n",
            "Epoch 89/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.1872 - accuracy: 0.4265 - val_loss: 2.8136 - val_accuracy: 0.3353\n",
            "Epoch 90/150\n",
            "64/64 [==============================] - 12s 186ms/step - loss: 2.1188 - accuracy: 0.4529 - val_loss: 2.8271 - val_accuracy: 0.3324\n",
            "Epoch 91/150\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 2.1560 - accuracy: 0.4343 - val_loss: 2.8218 - val_accuracy: 0.3382\n",
            "Epoch 92/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 2.0925 - accuracy: 0.4578 - val_loss: 2.7773 - val_accuracy: 0.3510\n",
            "Epoch 93/150\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.1412 - accuracy: 0.4314 - val_loss: 2.8142 - val_accuracy: 0.3431\n",
            "Epoch 94/150\n",
            "64/64 [==============================] - 10s 156ms/step - loss: 2.1047 - accuracy: 0.4529 - val_loss: 2.8606 - val_accuracy: 0.3422\n",
            "Epoch 95/150\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 2.0339 - accuracy: 0.4706 - val_loss: 2.8550 - val_accuracy: 0.3373\n",
            "Epoch 96/150\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 1.9793 - accuracy: 0.4784 - val_loss: 2.8930 - val_accuracy: 0.3284\n",
            "Epoch 97/150\n",
            "64/64 [==============================] - 10s 154ms/step - loss: 2.0371 - accuracy: 0.4569 - val_loss: 2.8608 - val_accuracy: 0.3373\n",
            "Epoch 98/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 2.0493 - accuracy: 0.4725 - val_loss: 2.8846 - val_accuracy: 0.3314\n",
            "Epoch 99/150\n",
            "64/64 [==============================] - 10s 147ms/step - loss: 1.9757 - accuracy: 0.5010 - val_loss: 2.8964 - val_accuracy: 0.3382\n",
            "Epoch 100/150\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 1.8937 - accuracy: 0.4951 - val_loss: 2.8107 - val_accuracy: 0.3569\n",
            "Epoch 101/150\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 1.9813 - accuracy: 0.4667 - val_loss: 2.8280 - val_accuracy: 0.3284\n",
            "Epoch 102/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 1.9584 - accuracy: 0.4775 - val_loss: 2.8845 - val_accuracy: 0.3373\n",
            "Epoch 103/150\n",
            "64/64 [==============================] - 12s 187ms/step - loss: 1.9057 - accuracy: 0.5029 - val_loss: 2.8624 - val_accuracy: 0.3382\n",
            "Epoch 104/150\n",
            "64/64 [==============================] - 10s 139ms/step - loss: 1.9241 - accuracy: 0.5000 - val_loss: 2.8107 - val_accuracy: 0.3480\n",
            "Epoch 105/150\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 1.9335 - accuracy: 0.4951 - val_loss: 2.8507 - val_accuracy: 0.3373\n",
            "Epoch 106/150\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 1.8520 - accuracy: 0.5039 - val_loss: 2.8366 - val_accuracy: 0.3471\n",
            "Epoch 107/150\n",
            "64/64 [==============================] - 12s 189ms/step - loss: 1.8692 - accuracy: 0.5069 - val_loss: 2.8296 - val_accuracy: 0.3422\n",
            "Epoch 108/150\n",
            "64/64 [==============================] - 10s 157ms/step - loss: 1.8276 - accuracy: 0.4853 - val_loss: 2.8688 - val_accuracy: 0.3480\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        "    #callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OxfordFlowers102-2.keras')"
      ],
      "metadata": {
        "id": "3tNYk4A0-VT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4324daheKXsn"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_batches, verbose=1, batch_size=BATCH_SIZE)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.ylim(0,10)\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iJRXw8RhICC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qMzpr_SZhHbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}