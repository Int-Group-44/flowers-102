{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Int-Group-44/flowers-102/blob/main/OxfordFlowers102CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "egaLH944BBD5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "dataset, dataset_info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "dataset_info\n",
        "test_set, training_set, validation_set = dataset['test'], dataset['train'], dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JAGNFt3PGE",
        "outputId": "e1a7d477-edcc-423a-b5cd-0afd298c5496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgSxJm7OYeKN"
      },
      "source": [
        "Importing TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ql9q6LSWMZRk"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "num_training_examples = 1020\n",
        "num_validation_examples = 1020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xwksk4asQhtr"
      },
      "outputs": [],
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    #label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "BATCH_SIZE = 16\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.shuffle(num_validation_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9WgfAXPgjFd5"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.RandomFlip(\"horizontal_and_vertical\", input_shape=input_shape))\n",
        "  model.add(layers.RandomRotation(20))\n",
        "  model.add(layers.RandomZoom(0.2))\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tF9v2wo9F8LW"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = make_model(input_shape=(IMAGE_RES, IMAGE_RES) + (3,), num_classes=102)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumHmqXelH38",
        "outputId": "ec6341ac-2df7-4f17-99ef-da8ed588da77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "64/64 [==============================] - 18s 148ms/step - loss: 5.3921 - accuracy: 0.0196 - val_loss: 4.6940 - val_accuracy: 0.0098\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 4.8414 - accuracy: 0.0157 - val_loss: 4.7131 - val_accuracy: 0.0098\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 4.7364 - accuracy: 0.0225 - val_loss: 4.6837 - val_accuracy: 0.0098\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 12s 185ms/step - loss: 4.6314 - accuracy: 0.0275 - val_loss: 4.6934 - val_accuracy: 0.0137\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 10s 149ms/step - loss: 4.5553 - accuracy: 0.0225 - val_loss: 4.6942 - val_accuracy: 0.0088\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 4.5443 - accuracy: 0.0314 - val_loss: 4.6677 - val_accuracy: 0.0186\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 4.4319 - accuracy: 0.0578 - val_loss: 4.5091 - val_accuracy: 0.0461\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 4.4141 - accuracy: 0.0471 - val_loss: 4.3551 - val_accuracy: 0.0637\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 10s 150ms/step - loss: 4.3808 - accuracy: 0.0422 - val_loss: 4.1656 - val_accuracy: 0.1088\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 4.3297 - accuracy: 0.0569 - val_loss: 4.0245 - val_accuracy: 0.1196\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 4.2368 - accuracy: 0.0824 - val_loss: 3.9636 - val_accuracy: 0.1539\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 4.1802 - accuracy: 0.0804 - val_loss: 3.8694 - val_accuracy: 0.1480\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 4.1213 - accuracy: 0.0902 - val_loss: 3.8262 - val_accuracy: 0.1431\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 4.0803 - accuracy: 0.1059 - val_loss: 3.7908 - val_accuracy: 0.1667\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 4.0275 - accuracy: 0.0990 - val_loss: 3.6986 - val_accuracy: 0.1647\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 10s 153ms/step - loss: 4.0143 - accuracy: 0.0971 - val_loss: 3.7176 - val_accuracy: 0.1667\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 9s 135ms/step - loss: 3.9261 - accuracy: 0.1206 - val_loss: 3.5955 - val_accuracy: 0.2108\n",
            "Epoch 18/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.9017 - accuracy: 0.1255 - val_loss: 3.6836 - val_accuracy: 0.1853\n",
            "Epoch 19/200\n",
            "64/64 [==============================] - 9s 140ms/step - loss: 3.7762 - accuracy: 0.1451 - val_loss: 3.6701 - val_accuracy: 0.1696\n",
            "Epoch 20/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 3.7443 - accuracy: 0.1343 - val_loss: 3.5077 - val_accuracy: 0.2000\n",
            "Epoch 21/200\n",
            "64/64 [==============================] - 10s 153ms/step - loss: 3.7184 - accuracy: 0.1520 - val_loss: 3.5104 - val_accuracy: 0.1873\n",
            "Epoch 22/200\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 3.6409 - accuracy: 0.1608 - val_loss: 3.4725 - val_accuracy: 0.2088\n",
            "Epoch 23/200\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 3.5985 - accuracy: 0.1784 - val_loss: 3.5652 - val_accuracy: 0.2029\n",
            "Epoch 24/200\n",
            "64/64 [==============================] - 9s 138ms/step - loss: 3.5713 - accuracy: 0.1706 - val_loss: 3.4435 - val_accuracy: 0.2088\n",
            "Epoch 25/200\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 3.4724 - accuracy: 0.1961 - val_loss: 3.3305 - val_accuracy: 0.2275\n",
            "Epoch 26/200\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 3.4974 - accuracy: 0.1902 - val_loss: 3.3180 - val_accuracy: 0.2265\n",
            "Epoch 27/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.4172 - accuracy: 0.2206 - val_loss: 3.4297 - val_accuracy: 0.2314\n",
            "Epoch 28/200\n",
            "64/64 [==============================] - 10s 142ms/step - loss: 3.3690 - accuracy: 0.2039 - val_loss: 3.3557 - val_accuracy: 0.2186\n",
            "Epoch 29/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 3.3183 - accuracy: 0.2108 - val_loss: 3.3306 - val_accuracy: 0.2333\n",
            "Epoch 30/200\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 3.3533 - accuracy: 0.2078 - val_loss: 3.2427 - val_accuracy: 0.2510\n",
            "Epoch 31/200\n",
            "64/64 [==============================] - 12s 184ms/step - loss: 3.2527 - accuracy: 0.2216 - val_loss: 3.1681 - val_accuracy: 0.2686\n",
            "Epoch 32/200\n",
            "64/64 [==============================] - 12s 184ms/step - loss: 3.1248 - accuracy: 0.2529 - val_loss: 3.1949 - val_accuracy: 0.2471\n",
            "Epoch 33/200\n",
            "64/64 [==============================] - 10s 151ms/step - loss: 3.1928 - accuracy: 0.2402 - val_loss: 3.1242 - val_accuracy: 0.2578\n",
            "Epoch 34/200\n",
            "64/64 [==============================] - 9s 143ms/step - loss: 3.0520 - accuracy: 0.2529 - val_loss: 3.1191 - val_accuracy: 0.2608\n",
            "Epoch 35/200\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 3.1494 - accuracy: 0.2392 - val_loss: 3.1455 - val_accuracy: 0.2735\n",
            "Epoch 36/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 3.0292 - accuracy: 0.2794 - val_loss: 3.0967 - val_accuracy: 0.2912\n",
            "Epoch 37/200\n",
            "64/64 [==============================] - 9s 139ms/step - loss: 3.0180 - accuracy: 0.2647 - val_loss: 3.0838 - val_accuracy: 0.2618\n",
            "Epoch 38/200\n",
            "64/64 [==============================] - 12s 188ms/step - loss: 2.9658 - accuracy: 0.2843 - val_loss: 3.1493 - val_accuracy: 0.2598\n",
            "Epoch 39/200\n",
            "64/64 [==============================] - 12s 184ms/step - loss: 2.8733 - accuracy: 0.2931 - val_loss: 3.1593 - val_accuracy: 0.2824\n",
            "Epoch 40/200\n",
            "64/64 [==============================] - 10s 155ms/step - loss: 2.9462 - accuracy: 0.2882 - val_loss: 3.0842 - val_accuracy: 0.2725\n",
            "Epoch 41/200\n",
            "64/64 [==============================] - 9s 134ms/step - loss: 2.7906 - accuracy: 0.3137 - val_loss: 3.3457 - val_accuracy: 0.2431\n",
            "Epoch 42/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.7924 - accuracy: 0.3020 - val_loss: 3.1258 - val_accuracy: 0.2755\n",
            "Epoch 43/200\n",
            "64/64 [==============================] - 11s 159ms/step - loss: 2.7319 - accuracy: 0.3265 - val_loss: 3.0385 - val_accuracy: 0.2922\n",
            "Epoch 44/200\n",
            "64/64 [==============================] - 13s 192ms/step - loss: 2.6334 - accuracy: 0.3343 - val_loss: 2.8735 - val_accuracy: 0.3216\n",
            "Epoch 45/200\n",
            "64/64 [==============================] - 10s 141ms/step - loss: 2.6484 - accuracy: 0.3333 - val_loss: 2.9347 - val_accuracy: 0.3108\n",
            "Epoch 46/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 2.6878 - accuracy: 0.3235 - val_loss: 3.2187 - val_accuracy: 0.2716\n",
            "Epoch 47/200\n",
            "64/64 [==============================] - 12s 168ms/step - loss: 2.5894 - accuracy: 0.3461 - val_loss: 3.0805 - val_accuracy: 0.2990\n",
            "Epoch 48/200\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 2.5945 - accuracy: 0.3451 - val_loss: 3.0223 - val_accuracy: 0.2980\n",
            "Epoch 49/200\n",
            "64/64 [==============================] - 10s 144ms/step - loss: 2.5247 - accuracy: 0.3588 - val_loss: 3.0474 - val_accuracy: 0.3206\n",
            "Epoch 50/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.4334 - accuracy: 0.3824 - val_loss: 3.0843 - val_accuracy: 0.3020\n",
            "Epoch 51/200\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 2.4527 - accuracy: 0.3647 - val_loss: 3.1385 - val_accuracy: 0.3078\n",
            "Epoch 52/200\n",
            "64/64 [==============================] - 12s 184ms/step - loss: 2.3684 - accuracy: 0.4039 - val_loss: 2.9964 - val_accuracy: 0.3235\n",
            "Epoch 53/200\n",
            "64/64 [==============================] - 12s 183ms/step - loss: 2.3970 - accuracy: 0.3912 - val_loss: 3.1449 - val_accuracy: 0.2873\n",
            "Epoch 54/200\n",
            "64/64 [==============================] - 9s 142ms/step - loss: 2.3054 - accuracy: 0.3951 - val_loss: 2.9991 - val_accuracy: 0.3412\n",
            "Epoch 55/200\n",
            "64/64 [==============================] - 9s 136ms/step - loss: 2.2802 - accuracy: 0.4088 - val_loss: 3.0545 - val_accuracy: 0.3363\n",
            "Epoch 56/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.2531 - accuracy: 0.4069 - val_loss: 3.0540 - val_accuracy: 0.3265\n",
            "Epoch 57/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.2625 - accuracy: 0.4127 - val_loss: 2.8675 - val_accuracy: 0.3608\n",
            "Epoch 58/200\n",
            "64/64 [==============================] - 10s 146ms/step - loss: 2.2398 - accuracy: 0.4216 - val_loss: 3.0194 - val_accuracy: 0.3382\n",
            "Epoch 59/200\n",
            "64/64 [==============================] - 12s 184ms/step - loss: 2.1044 - accuracy: 0.4353 - val_loss: 3.0031 - val_accuracy: 0.3304\n",
            "Epoch 60/200\n",
            "64/64 [==============================] - 10s 143ms/step - loss: 2.2218 - accuracy: 0.4382 - val_loss: 3.1700 - val_accuracy: 0.3010\n",
            "Epoch 61/200\n",
            "64/64 [==============================] - 10s 145ms/step - loss: 2.1169 - accuracy: 0.4559 - val_loss: 3.2040 - val_accuracy: 0.3108\n",
            "Epoch 62/200\n",
            "64/64 [==============================] - 9s 137ms/step - loss: 2.0935 - accuracy: 0.4471 - val_loss: 3.1146 - val_accuracy: 0.3588\n",
            "Epoch 63/200\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.9887 - accuracy: 0.4647"
          ]
        }
      ],
      "source": [
        "\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.000075),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        "    #callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tloss1 = history.history['loss']\n",
        "vloss1 = history.history['val_loss']\n",
        "tacc1 = history.history['accuracy']\n",
        "vacc1 = history.history['val_accuracy']"
      ],
      "metadata": {
        "id": "mD33c-dQEKYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#keras.shutils.plot_model(model, ow_shapes=True)\n",
        "\n",
        "epochs = 200\n",
        "\n",
        "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        "    #callbacks=[reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "id": "a2yLllbgBxDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tloss2 = history.history['loss']\n",
        "vloss2 = history.history['val_loss']\n",
        "tacc2 = history.history['accuracy']\n",
        "vacc2 = history.history['val_accuracy']"
      ],
      "metadata": {
        "id": "j7YNON-AElOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OxfordFlowers102-2.keras')"
      ],
      "metadata": {
        "id": "3tNYk4A0-VT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4324daheKXsn"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_batches, verbose=1, batch_size=BATCH_SIZE)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tloss1 + tloss2)\n",
        "plt.ylim(0,10)\n",
        "plt.plot(vloss1 + vloss2)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iJRXw8RhICC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tacc1 + tacc2)\n",
        "plt.plot(vacc1 + vacc2)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qMzpr_SZhHbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}