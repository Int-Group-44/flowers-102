{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Int-Group-44/flowers-102/blob/main/OxfordFlowers102CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "egaLH944BBD5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "#device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "dataset, dataset_info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)\n",
        "dataset_info\n",
        "test_set, training_set, validation_set = dataset['test'], dataset['train'], dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JAGNFt3PGE",
        "outputId": "d42d9925-9b91-4178-836f-3fd8b9959269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Physical devices cannot be modified after being initialized\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n",
        "\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgSxJm7OYeKN"
      },
      "source": [
        "Importing TensorFlow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ql9q6LSWMZRk"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset_info.features['label'].num_classes\n",
        "num_training_examples = 1020\n",
        "num_validation_examples = 1020"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xwksk4asQhtr"
      },
      "outputs": [],
      "source": [
        "IMAGE_RES = 224\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    #label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "BATCH_SIZE = 64\n",
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_set.shuffle(num_validation_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = test_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9WgfAXPgjFd5"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape, num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.RandomFlip(\"horizontal\", input_shape=input_shape))\n",
        "  model.add(layers.RandomRotation(20))\n",
        "  model.add(layers.RandomZoom(0.2))\n",
        "  #model.add(layers.RandomContrast(factor=(0.0, 0.1)))\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu')) #64 filters, kernel size 3x3, stride = 1\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu')) \n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())                                   #2x2 pooling, stride of 2\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(256, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(512, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D())\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(4096, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  #model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(4096, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  #model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  #model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(num_classes))\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tF9v2wo9F8LW"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pumHmqXelH38",
        "outputId": "80695a0f-a92b-4412-e47e-a44c1568ff2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "16/16 [==============================] - 81s 3s/step - loss: 5.2723 - accuracy: 0.0265 - val_loss: 5.0286 - val_accuracy: 0.0118 - lr: 0.0100\n",
            "Epoch 2/150\n",
            "16/16 [==============================] - 20s 1s/step - loss: 4.6734 - accuracy: 0.0559 - val_loss: 4.6606 - val_accuracy: 0.0167 - lr: 0.0100\n",
            "Epoch 3/150\n",
            "16/16 [==============================] - 21s 1s/step - loss: 4.0804 - accuracy: 0.1137 - val_loss: 4.5629 - val_accuracy: 0.0216 - lr: 0.0100\n",
            "Epoch 4/150\n",
            "16/16 [==============================] - 20s 1s/step - loss: 3.4338 - accuracy: 0.1912 - val_loss: 4.6118 - val_accuracy: 0.0186 - lr: 0.0100\n",
            "Epoch 5/150\n",
            "16/16 [==============================] - 21s 1s/step - loss: 3.0715 - accuracy: 0.2392 - val_loss: 4.6509 - val_accuracy: 0.0196 - lr: 0.0100\n",
            "Epoch 6/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 2.7894 - accuracy: 0.3029 - val_loss: 4.8086 - val_accuracy: 0.0186 - lr: 0.0100\n",
            "Epoch 7/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 2.2787 - accuracy: 0.4059 - val_loss: 4.8287 - val_accuracy: 0.0157 - lr: 0.0050\n",
            "Epoch 8/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 2.0236 - accuracy: 0.4500 - val_loss: 4.8932 - val_accuracy: 0.0186 - lr: 0.0050\n",
            "Epoch 9/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.8420 - accuracy: 0.5186 - val_loss: 4.9056 - val_accuracy: 0.0265 - lr: 0.0050\n",
            "Epoch 10/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.6859 - accuracy: 0.5402 - val_loss: 4.9146 - val_accuracy: 0.0294 - lr: 0.0025\n",
            "Epoch 11/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.5592 - accuracy: 0.5951 - val_loss: 4.8980 - val_accuracy: 0.0353 - lr: 0.0025\n",
            "Epoch 12/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.4842 - accuracy: 0.6265 - val_loss: 4.9400 - val_accuracy: 0.0333 - lr: 0.0025\n",
            "Epoch 13/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.4180 - accuracy: 0.6343 - val_loss: 4.9727 - val_accuracy: 0.0461 - lr: 0.0012\n",
            "Epoch 14/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.3642 - accuracy: 0.6745 - val_loss: 4.9770 - val_accuracy: 0.0471 - lr: 0.0012\n",
            "Epoch 15/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.2996 - accuracy: 0.6745 - val_loss: 4.9393 - val_accuracy: 0.0549 - lr: 0.0012\n",
            "Epoch 16/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 1.2244 - accuracy: 0.7020 - val_loss: 4.8970 - val_accuracy: 0.0578 - lr: 6.2500e-04\n",
            "Epoch 17/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.2567 - accuracy: 0.6912 - val_loss: 4.8331 - val_accuracy: 0.0647 - lr: 6.2500e-04\n",
            "Epoch 18/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.2611 - accuracy: 0.6951 - val_loss: 4.7462 - val_accuracy: 0.0696 - lr: 6.2500e-04\n",
            "Epoch 19/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1772 - accuracy: 0.7157 - val_loss: 4.6390 - val_accuracy: 0.0833 - lr: 3.1250e-04\n",
            "Epoch 20/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.2374 - accuracy: 0.6912 - val_loss: 4.5206 - val_accuracy: 0.0873 - lr: 3.1250e-04\n",
            "Epoch 21/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.1711 - accuracy: 0.7137 - val_loss: 4.4002 - val_accuracy: 0.1010 - lr: 3.1250e-04\n",
            "Epoch 22/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1911 - accuracy: 0.7255 - val_loss: 4.2630 - val_accuracy: 0.1176 - lr: 3.1250e-04\n",
            "Epoch 23/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1654 - accuracy: 0.7373 - val_loss: 4.1503 - val_accuracy: 0.1402 - lr: 3.1250e-04\n",
            "Epoch 24/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1629 - accuracy: 0.7206 - val_loss: 4.0240 - val_accuracy: 0.1559 - lr: 3.1250e-04\n",
            "Epoch 25/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1496 - accuracy: 0.7216 - val_loss: 3.9038 - val_accuracy: 0.1794 - lr: 3.1250e-04\n",
            "Epoch 26/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1751 - accuracy: 0.7314 - val_loss: 3.7857 - val_accuracy: 0.2010 - lr: 3.1250e-04\n",
            "Epoch 27/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1126 - accuracy: 0.7441 - val_loss: 3.6918 - val_accuracy: 0.2176 - lr: 3.1250e-04\n",
            "Epoch 28/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1301 - accuracy: 0.7363 - val_loss: 3.6098 - val_accuracy: 0.2294 - lr: 3.1250e-04\n",
            "Epoch 29/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.1130 - accuracy: 0.7431 - val_loss: 3.5511 - val_accuracy: 0.2324 - lr: 3.1250e-04\n",
            "Epoch 30/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1280 - accuracy: 0.7363 - val_loss: 3.5105 - val_accuracy: 0.2441 - lr: 3.1250e-04\n",
            "Epoch 31/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1252 - accuracy: 0.7284 - val_loss: 3.4639 - val_accuracy: 0.2520 - lr: 3.1250e-04\n",
            "Epoch 32/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0733 - accuracy: 0.7510 - val_loss: 3.4353 - val_accuracy: 0.2539 - lr: 3.1250e-04\n",
            "Epoch 33/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.0896 - accuracy: 0.7500 - val_loss: 3.4137 - val_accuracy: 0.2608 - lr: 3.1250e-04\n",
            "Epoch 34/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.1089 - accuracy: 0.7353 - val_loss: 3.3905 - val_accuracy: 0.2598 - lr: 3.1250e-04\n",
            "Epoch 35/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 1.1252 - accuracy: 0.7324 - val_loss: 3.3692 - val_accuracy: 0.2598 - lr: 3.1250e-04\n",
            "Epoch 36/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0859 - accuracy: 0.7275 - val_loss: 3.3612 - val_accuracy: 0.2618 - lr: 3.1250e-04\n",
            "Epoch 37/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.0416 - accuracy: 0.7549 - val_loss: 3.3494 - val_accuracy: 0.2618 - lr: 3.1250e-04\n",
            "Epoch 38/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.0678 - accuracy: 0.7637 - val_loss: 3.3403 - val_accuracy: 0.2686 - lr: 3.1250e-04\n",
            "Epoch 39/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0641 - accuracy: 0.7422 - val_loss: 3.3388 - val_accuracy: 0.2686 - lr: 3.1250e-04\n",
            "Epoch 40/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 1.0493 - accuracy: 0.7480 - val_loss: 3.3340 - val_accuracy: 0.2667 - lr: 3.1250e-04\n",
            "Epoch 41/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.0726 - accuracy: 0.7588 - val_loss: 3.3321 - val_accuracy: 0.2716 - lr: 3.1250e-04\n",
            "Epoch 42/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9952 - accuracy: 0.7814 - val_loss: 3.3299 - val_accuracy: 0.2696 - lr: 3.1250e-04\n",
            "Epoch 43/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.0447 - accuracy: 0.7618 - val_loss: 3.3285 - val_accuracy: 0.2716 - lr: 3.1250e-04\n",
            "Epoch 44/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.0131 - accuracy: 0.7569 - val_loss: 3.3297 - val_accuracy: 0.2775 - lr: 3.1250e-04\n",
            "Epoch 45/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9597 - accuracy: 0.7853 - val_loss: 3.3288 - val_accuracy: 0.2765 - lr: 3.1250e-04\n",
            "Epoch 46/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9667 - accuracy: 0.7824 - val_loss: 3.3358 - val_accuracy: 0.2814 - lr: 3.1250e-04\n",
            "Epoch 47/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9692 - accuracy: 0.7676 - val_loss: 3.3321 - val_accuracy: 0.2784 - lr: 1.5625e-04\n",
            "Epoch 48/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0701 - accuracy: 0.7422 - val_loss: 3.3309 - val_accuracy: 0.2775 - lr: 1.5625e-04\n",
            "Epoch 49/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9867 - accuracy: 0.7686 - val_loss: 3.3313 - val_accuracy: 0.2735 - lr: 1.5625e-04\n",
            "Epoch 50/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 0.9823 - accuracy: 0.7686 - val_loss: 3.3327 - val_accuracy: 0.2735 - lr: 7.8125e-05\n",
            "Epoch 51/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9876 - accuracy: 0.7716 - val_loss: 3.3326 - val_accuracy: 0.2745 - lr: 7.8125e-05\n",
            "Epoch 52/150\n",
            "16/16 [==============================] - 24s 1s/step - loss: 1.0665 - accuracy: 0.7510 - val_loss: 3.3352 - val_accuracy: 0.2725 - lr: 7.8125e-05\n",
            "Epoch 53/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0279 - accuracy: 0.7676 - val_loss: 3.3359 - val_accuracy: 0.2706 - lr: 3.9062e-05\n",
            "Epoch 54/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9756 - accuracy: 0.7765 - val_loss: 3.3375 - val_accuracy: 0.2696 - lr: 3.9062e-05\n",
            "Epoch 55/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.9859 - accuracy: 0.7725 - val_loss: 3.3371 - val_accuracy: 0.2706 - lr: 3.9062e-05\n",
            "Epoch 56/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0275 - accuracy: 0.7578 - val_loss: 3.3370 - val_accuracy: 0.2706 - lr: 1.9531e-05\n",
            "Epoch 57/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9957 - accuracy: 0.7824 - val_loss: 3.3382 - val_accuracy: 0.2696 - lr: 1.9531e-05\n",
            "Epoch 58/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.9865 - accuracy: 0.7667 - val_loss: 3.3390 - val_accuracy: 0.2686 - lr: 1.9531e-05\n",
            "Epoch 59/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0199 - accuracy: 0.7549 - val_loss: 3.3394 - val_accuracy: 0.2706 - lr: 9.7656e-06\n",
            "Epoch 60/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 0.9658 - accuracy: 0.7863 - val_loss: 3.3402 - val_accuracy: 0.2706 - lr: 9.7656e-06\n",
            "Epoch 61/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9998 - accuracy: 0.7676 - val_loss: 3.3400 - val_accuracy: 0.2686 - lr: 9.7656e-06\n",
            "Epoch 62/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.0847 - accuracy: 0.7461 - val_loss: 3.3398 - val_accuracy: 0.2706 - lr: 4.8828e-06\n",
            "Epoch 63/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9780 - accuracy: 0.7775 - val_loss: 3.3396 - val_accuracy: 0.2696 - lr: 4.8828e-06\n",
            "Epoch 64/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 1.0536 - accuracy: 0.7559 - val_loss: 3.3403 - val_accuracy: 0.2696 - lr: 4.8828e-06\n",
            "Epoch 65/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 0.9812 - accuracy: 0.7598 - val_loss: 3.3408 - val_accuracy: 0.2696 - lr: 2.4414e-06\n",
            "Epoch 66/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9600 - accuracy: 0.7902 - val_loss: 3.3410 - val_accuracy: 0.2686 - lr: 2.4414e-06\n",
            "Epoch 67/150\n",
            "16/16 [==============================] - 28s 2s/step - loss: 1.0032 - accuracy: 0.7598 - val_loss: 3.3408 - val_accuracy: 0.2696 - lr: 2.4414e-06\n",
            "Epoch 68/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0445 - accuracy: 0.7480 - val_loss: 3.3406 - val_accuracy: 0.2716 - lr: 1.2207e-06\n",
            "Epoch 69/150\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.9976 - accuracy: 0.7794 - val_loss: 3.3409 - val_accuracy: 0.2716 - lr: 1.2207e-06\n",
            "Epoch 70/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9902 - accuracy: 0.7853 - val_loss: 3.3409 - val_accuracy: 0.2706 - lr: 1.2207e-06\n",
            "Epoch 71/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0001 - accuracy: 0.7637 - val_loss: 3.3411 - val_accuracy: 0.2716 - lr: 1.0000e-06\n",
            "Epoch 72/150\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9796 - accuracy: 0.7735 - val_loss: 3.3417 - val_accuracy: 0.2706 - lr: 1.0000e-06\n",
            "Epoch 73/150\n",
            "16/16 [==============================] - 27s 2s/step - loss: 1.0301 - accuracy: 0.7696 - val_loss: 3.3409 - val_accuracy: 0.2706 - lr: 1.0000e-06\n",
            "Epoch 74/150\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.0290 - accuracy: 0.7402"
          ]
        }
      ],
      "source": [
        "model = make_model(input_shape=(IMAGE_RES, IMAGE_RES) + (3,), num_classes=102)\n",
        "#keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.000001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_batches,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_batches,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_batch_size=BATCH_SIZE,\n",
        "    verbose=1,\n",
        "    callbacks=[reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('OxfordFlowers102-2.keras')"
      ],
      "metadata": {
        "id": "3tNYk4A0-VT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4324daheKXsn",
        "outputId": "76f52dbc-a7ed-410a-a2d2-9cf1425db1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "193/193 [==============================] - 27s 140ms/step - loss: 3.2010 - accuracy: 0.2420\n",
            "Test accuracy: 0.2419905662536621\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_batches, verbose=1, batch_size=BATCH_SIZE)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}